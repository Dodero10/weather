{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.ndimage as ndimage\n",
    "import os\n",
    "from google.cloud import bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"./dodero.json\"\n",
    "client = bigquery.Client()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = {\n",
    "    \"U10\": \"u10\",\n",
    "    \"V10\": \"v10\",\n",
    "    \"2m Dewpoint Temperature\": \"d2m\",\n",
    "    \"2m Temperature\": \"t2m\",\n",
    "    \"Mean Sea Level Pressure\": \"msl\",\n",
    "    \"Sea Surface Temperature\": \"sst\",\n",
    "    \"Surface Pressure\": \"sp\",\n",
    "    \"Total Cloud Cover\": \"tcc\",\n",
    "    \"Total Column Cloud Ice Water\": \"tciw\",\n",
    "    \"Total Column Liquid Water\": \"tclw\"\n",
    "}\n",
    "\n",
    "df = {}\n",
    "for attribute in attributes.values():\n",
    "    QUERY = f'''\n",
    "        SELECT\n",
    "            {attribute}\n",
    "        FROM\n",
    "            `strong-ward-437213-j6.bigdata_20241.weather_all`\n",
    "        WHERE\n",
    "            time >= '2024-09-07 00:00:00 UTC'\n",
    "            AND time <= '2024-09-07 23:00:00 UTC'\n",
    "        ORDER BY\n",
    "            time, latitude DESC, longitude\n",
    "    '''\n",
    "    \n",
    "    # Execute the query and get results\n",
    "    query_job = client.query(QUERY)\n",
    "    rows = query_job.result()\n",
    "\n",
    "    # Convert results to a numpy array\n",
    "    data = [row[0] for row in rows]\n",
    "\n",
    "    # Process data and create a dictionary of 3D arrays for each attribute\n",
    "    df[attribute] =  np.reshape(data, (24, 65, 41)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def distance_matrix(lons,lats):\n",
    "    '''Calculates the distances (in km) between any two cities based on the formulas\n",
    "    c = sin(lati1)*sin(lati2)+cos(longi1-longi2)*cos(lati1)*cos(lati2)\n",
    "    d = EARTH_RADIUS*Arccos(c)\n",
    "    where EARTH_RADIUS is in km and the angles are in radians.\n",
    "    Source: http://mathforum.org/library/drmath/view/54680.html\n",
    "    This function returns the matrix.'''\n",
    "\n",
    "    EARTH_RADIUS = 6378.1\n",
    "    X = len(lons)\n",
    "    Y = len(lats)\n",
    "    assert X == Y, 'lons and lats must have same number of elements'\n",
    "\n",
    "    d = np.zeros((X,X))\n",
    "\n",
    "    #Populate the matrix.\n",
    "    for i2 in range(len(lons)):\n",
    "        lati2 = lats[i2]\n",
    "        loni2 = lons[i2]\n",
    "        c = np.sin(np.radians(lats)) * np.sin(np.radians(lati2)) + \\\n",
    "            np.cos(np.radians(lons-loni2)) * \\\n",
    "            np.cos(np.radians(lats)) * np.cos(np.radians(lati2))\n",
    "        d[c<1,i2] = EARTH_RADIUS * np.arccos(c[c<1])\n",
    "\n",
    "    return d\n",
    "\n",
    "def diameter(area):\n",
    "    r = np.sqrt((area/np.pi))\n",
    "    return (r*2)\n",
    "\n",
    "def major_ratio(area, ratio):\n",
    "    # given the area and ratio of minor to major axis of an ellipse, returns the length of the major axis\n",
    "    maj = np.sqrt(area/(np.pi*ratio))\n",
    "    return maj \n",
    "\n",
    "def major_ecc(area, ecc):\n",
    "    # given the area and eccentricity of an ellipse, returns the length of the major axis    \n",
    "    denom = np.pi*np.sqrt(1-(ecc**2))\n",
    "    maj = np.sqrt(area/denom)\n",
    "    return maj\n",
    "\n",
    "def ecc(ratio):\n",
    "    #given ratio of a/b, calculates eccentricity of ellipse\n",
    "    e = (ratio)*(np.sqrt((ratio**-2)-1))\n",
    "    return e\n",
    "\n",
    "def nanmean(array, axis=None):\n",
    "    return np.mean(np.ma.masked_array(array, np.isnan(array)), axis)\n",
    "\n",
    "def len_deg_lon(lat):\n",
    "    '''\n",
    "    Returns the length of one degree of longitude (at latitude\n",
    "    specified) in km.\n",
    "    '''\n",
    "\n",
    "    R = 6371. # Radius of Earth [km]\n",
    "\n",
    "    return (np.pi/180.) * R * np.cos( lat * np.pi/180. )\n",
    "\n",
    "def spatial_filter(msl, lon, lat, res, cut_lon, cut_lat):\n",
    "    '''\n",
    "    Performs a spatial filter, removing all features with\n",
    "    wavelenth scales larger than cut_lon in longitude and\n",
    "    cut_lat in latitude from msl (defined in grid given\n",
    "    by lon and lat).  msl has spatial resolution of res\n",
    "    and land identified by np.nan's\n",
    "    '''\n",
    "\n",
    "    msl_filt = np.zeros(msl.shape)\n",
    "\n",
    "    # see Chelton et al, Prog. Ocean., 2011 for explanation of factor of 1/5\n",
    "    sig_lon = (cut_lon/5.) / res\n",
    "    sig_lat = (cut_lat/5.) / res\n",
    "\n",
    "    land = np.isnan(msl)\n",
    "    msl[land] = nanmean(msl)\n",
    "\n",
    "    msl_filt =  ndimage.gaussian_filter(msl, [sig_lat, sig_lon])\n",
    "\n",
    "    msl_filt[land] = np.nan\n",
    "\n",
    "    return msl_filt\n",
    "\n",
    "\n",
    "def detect_storms(msl, wind_speed, lon, lat, res, order, Npix_min, Npix_max, rel_amp_thresh, d_thresh, cyc, cut_lon, cut_lat, globe=False):\n",
    "    '''\n",
    "    Detect storms present in msl which satisfy the criteria.\n",
    "    Algorithm is an adaptation of an eddy detection algorithm,\n",
    "    outlined in Chelton et al., Prog. ocean., 2011, App. B.2,\n",
    "    with modifications needed for storm detection.\n",
    "\n",
    "    msl is a 2D array specified on grid defined by lat and lon.\n",
    "\n",
    "    res is the horizontal grid resolution in degrees of msl\n",
    "\n",
    "    Npix_min is the minimum number of pixels within which an\n",
    "    extremum of msl must lie (recommended: 9).\n",
    "\n",
    "    cyc = 'cyclonic' or 'anticyclonic' specifies type of system\n",
    "    to be detected (cyclonic storm or high-pressure systems)\n",
    "\n",
    "    globe is an option to detect storms on a globe, i.e. with periodic\n",
    "    boundaries in the West/East. Note that if using this option the \n",
    "    supplied longitudes must be positive only (i.e. 0..360 not -180..+180).\n",
    "\n",
    "    Function outputs lon, lat coordinates of detected storms\n",
    "    '''\n",
    "\n",
    "    len_deg_lat = 111.325 # length of 1 degree of latitude [km]\n",
    "\n",
    "    msl = spatial_filter(msl, lon, lat, res, cut_lon, cut_lat)\n",
    "    # Need to repeat global msl to the West and East to properly detect around the edge\n",
    "    if globe:\n",
    "        dl = 20. # Degrees longitude to repeat on East and West of edge\n",
    "        iEast = np.where(lon >= 360. - dl)[0][0]\n",
    "        iWest = np.where(lon <= dl)[0][-1]\n",
    "        lon = np.append(lon[iEast:]-360, np.append(lon, lon[:iWest]+360))\n",
    "        msl = np.append(msl[:,iEast:], np.append(msl, msl[:,:iWest], axis=1), axis=1)\n",
    "\n",
    "    llon, llat = np.meshgrid(lon, lat)\n",
    "\n",
    "    lon_storms = np.array([])\n",
    "    lat_storms = np.array([])\n",
    "    amp_storms = np.array([])\n",
    "    area_storms = np.array([])\n",
    "    max_wind_speeds = np.array([])\n",
    "    regions_storm = []\n",
    "    \n",
    "\n",
    "    # ssh_crits is an array of ssh levels over which to perform storm detection loop\n",
    "    # ssh_crits increasing for 'cyclonic', decreasing for 'anticyclonic'\n",
    "    ssh_crits = np.linspace(np.nanmin(msl), np.nanmax(msl), 200)\n",
    "    ssh_crits = np.array([100000])\n",
    "    if order == 'topdown':\n",
    "        ssh_crits = np.flipud(ssh_crits)\n",
    "\n",
    "    # loop over ssh_crits and remove interior pixels of detected storms from subsequent loop steps\n",
    "    for ssh_crit in ssh_crits:\n",
    " \n",
    "    # 1. Find all regions with eta greater (less than) than ssh_crit for anticyclonic (cyclonic) storms (Chelton et al. 2011, App. B.2, criterion 1)\n",
    "        if cyc == 'anticyclonic':\n",
    "            regions, nregions = ndimage.label( (msl>ssh_crit).astype(int) )\n",
    "        elif cyc == 'cyclonic':\n",
    "            regions, nregions = ndimage.label( (msl<ssh_crit).astype(int) )\n",
    "\n",
    "        for iregion in range(nregions):\n",
    " \n",
    "    # 2. Calculate number of pixels comprising detected region, reject if not within >= Npix_min\n",
    "            region = (regions==iregion+1).astype(int)\n",
    "            region_Npix = region.sum()\n",
    "            storm_area_within_limits = ((region_Npix >= Npix_min) * (region_Npix <= Npix_max))\n",
    " \n",
    "    # 3. Detect presence of local maximum (minimum) for anticylones (cyclones), reject if non-existents\n",
    "            interior = ndimage.binary_erosion(region)\n",
    "            #exterior = region.astype(bool) - interior\n",
    "            exterior = np.logical_xor(region.astype(bool), interior)\n",
    "            if interior.sum() == 0:\n",
    "                continue\n",
    "            if cyc == 'anticyclonic':\n",
    "                has_internal_ext = msl[interior].max() > msl[exterior].max()\n",
    "            elif cyc == 'cyclonic':\n",
    "                has_internal_ext = msl[interior].min() < msl[exterior].min()\n",
    " \n",
    "    # 4. Find amplitude of region, reject if < amp_thresh\n",
    "            if cyc == 'anticyclonic':\n",
    "                amp_abs = msl[interior].max()\n",
    "                amp = amp_abs - msl[exterior].mean()\n",
    "            elif cyc == 'cyclonic':\n",
    "                amp_abs = msl[interior].min()\n",
    "                amp = msl[exterior].mean() - amp_abs\n",
    "            #amp_thresh = np.abs(np.diff(ssh_crits)[0])\n",
    "            is_tall_storm = amp >= rel_amp_thresh\n",
    "\n",
    "    # 5. Find maximum linear dimension of region, reject if < d_thresh\n",
    "            lon_ext = llon[exterior]\n",
    "            lat_ext = llat[exterior]\n",
    "            d = distance_matrix(lon_ext, lat_ext)\n",
    "            is_small_storm = d.max() < d_thresh\n",
    "    \n",
    "\n",
    "    # Quit loop if these are not satisfied\n",
    "            if np.logical_not(storm_area_within_limits * has_internal_ext * is_tall_storm * is_small_storm):\n",
    "                continue\n",
    " \n",
    "    # Detected storms:\n",
    "            if (storm_area_within_limits * has_internal_ext * is_tall_storm * is_small_storm):\n",
    "                # find centre of mass of storm\n",
    "                storm_object_with_mass = msl * region\n",
    "                storm_object_with_mass[np.isnan(storm_object_with_mass)] = 0\n",
    "                min_pressure_pos = np.unravel_index(np.argmin(msl), msl.shape)\n",
    "    \n",
    "                # Chuyển đổi chỉ số vị trí (min_pressure_pos) thành tọa độ kinh độ và vĩ độ\n",
    "                j_min, i_min = min_pressure_pos\n",
    "                lon_cen = np.interp(i_min, range(0,len(lon)), lon)\n",
    "                lat_cen = np.interp(j_min, range(0,len(lat)), lat)\n",
    "                # Remove storms detected outside global domain (lon < 0, > 360)\n",
    "                #if globe * (lon_cen >= 0.) * (lon_cen <= 360.):\n",
    "                \n",
    "                # Save storm\n",
    "                lon_storms = np.append(lon_storms, lon_cen)\n",
    "                lat_storms = np.append(lat_storms, lat_cen)\n",
    "                \n",
    "                # assign (and calculated) amplitude, area, and scale of storms\n",
    "                amp_storms = np.append(amp_storms, amp_abs)\n",
    "                area = region_Npix * res**2 * len_deg_lat * len_deg_lon(lat_cen) # [km**2]\n",
    "                area_storms = np.append(area_storms, area)                \n",
    "                # remove its interior pixels from further storm detection\n",
    "                storm_mask = np.ones(msl.shape)\n",
    "                storm_mask[interior.astype(int)==1] = np.nan\n",
    "                storm_mask = msl * storm_mask\n",
    "                region_storm = np.isnan(storm_mask).astype(int)\n",
    "                regions_storm.append(region_storm)\n",
    "                max_wind_speed = (wind_speed*region_storm).max()\n",
    "                max_wind_speeds = np.append(max_wind_speeds, max_wind_speed)\n",
    "\n",
    "    return lon_storms, lat_storms, amp_storms, max_wind_speeds, area_storms, regions_storm, \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "msl = df[\"msl\"]\n",
    "lon = np.arange(102, 112.25, 0.25)\n",
    "lat = np.arange(24, 7.75,-0.25)\n",
    "u10 = df[\"u10\"]\n",
    "v10 = df[\"v10\"]\n",
    "wind_speed = np.sqrt(u10*u10+v10*v10)\n",
    "res = 0.25 \n",
    "order = 'topdown' \n",
    "Npix_min = 9\n",
    "Npix_max = 6000  \n",
    "rel_amp_thresh = 100  \n",
    "d_thresh = 2500  \n",
    "cyc = 'cyclonic'  \n",
    "cut_lon = 1  #\n",
    "cut_lat = 1  \n",
    "globe = False  \n",
    "\n",
    "lon_storms, lat_storms, amp_storms, max_wind_speeds, area_storms, regions_storm = detect_storms(\n",
    "    msl[0, :, :], wind_speed[0, :, :], lon, lat, res, order, Npix_min, Npix_max, rel_amp_thresh, \n",
    "    d_thresh, cyc, cut_lon, cut_lat, globe\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([108.25]),\n",
       " array([20.5]),\n",
       " array([97577.12187712]),\n",
       " array([25.74671071]),\n",
       " array([379006.80564999]),\n",
       " [array([[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]])])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lon_storms, lat_storms, amp_storms, max_wind_speeds, area_storms, regions_storm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1, 65, 41)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Tạo các biến mới từ các danh sách ban đầu\n",
    "lon_storms_array = np.array(lon_storms)\n",
    "lat_storms_array = np.array(lat_storms)\n",
    "amp_storms_array = np.array(amp_storms)\n",
    "wind_speeds_array = np.array(max_wind_speeds)  # Đảm bảo không bị lỗi gõ phím\n",
    "area_storms_array = np.array(area_storms)\n",
    "regions_array = np.array(regions_storm)\n",
    "\n",
    "# In ra kích thước của các biến mới\n",
    "print(lon_storms_array.shape)\n",
    "print(lat_storms_array.shape)\n",
    "print(amp_storms_array.shape)\n",
    "print(wind_speeds_array.shape)\n",
    "print(area_storms_array.shape)\n",
    "print(regions_array.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
